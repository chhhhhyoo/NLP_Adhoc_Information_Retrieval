{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/cran.qry\", 'r') as file:\n",
    "    cran_qry_content = file.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'the', 'an', 'and', 'or', 'but', 'about', 'above']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data/stop_list.py', 'r') as file:\n",
    "    stop_list_content = file.read()\n",
    "\n",
    "stop_list_content[:100]\n",
    "\n",
    "# Changing the text we extracted into a format that is desired.\n",
    "start = stop_list_content.find('[')\n",
    "end = stop_list_content.find(']', start) + 1 # Search after the start\n",
    "stop_word_list = eval(stop_list_content[start:end])\n",
    "\n",
    "stop_word_list[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/cran.all.1400\", 'r') as file:\n",
    "    cran_all_content = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "\n",
    "import re\n",
    "\n",
    "# Clean and tokenize text\n",
    "def clean_tokenize(text, stemmer = PorterStemmer()):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\d+', '', text) # Remove number\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stop_words\n",
    "    tokens = [word for word in tokens if word not in stop_word_list]\n",
    "    # Apply stemming\n",
    "    tokens = [stemmer.stem(word) for word in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse cran.qry(QUERY) content\n",
    "def parse_cran_qry(content) :\n",
    "    queries = {}\n",
    "    current_id = \"\"\n",
    "    lines = content.split('\\n')\n",
    "    for line in lines:\n",
    "        if line.startswith('.I'): # Start of new query\n",
    "            current_id = line.split(' ')[1]\n",
    "            queries[current_id] = \"\"\n",
    "        elif line.startswith('.W'):\n",
    "            continue\n",
    "        else :\n",
    "            queries[current_id] += line + \" \"\n",
    "    return queries\n",
    "\n",
    "# Parse cran.qry\n",
    "queries = parse_cran_qry(cran_qry_content)\n",
    "\n",
    "# Clean and tokenize each query\n",
    "tokenized_qry = {qid: clean_tokenize(query) for qid, query in queries.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse .W part (abstracts) from cran.all.1400\n",
    "def parse_cran_abstracts(content) : \n",
    "    abstracts = {}\n",
    "    current_id = \"\"\n",
    "    lines = content.split('\\n')\n",
    "    in_abstract = False\n",
    "    for line in lines:\n",
    "        if line.startswith('.I'):\n",
    "            current_id = line.split(' ')[1]\n",
    "            in_abstract = False\n",
    "        elif line.startswith('.W') :\n",
    "            in_abstract = True\n",
    "            abstracts[current_id] = \"\"\n",
    "        elif in_abstract :\n",
    "            abstracts[current_id] += line + \" \"\n",
    "    return abstracts\n",
    "\n",
    "# Parse the abstracts from cran.all.1400\n",
    "abstracts = parse_cran_abstracts(cran_all_content)\n",
    "\n",
    "# Clean and tokenize each abstract\n",
    "tokenized_abstr = {doc_id : clean_tokenize(abstract) for doc_id, abstract in abstracts.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                       Version\n",
      "----------------------------- ------------\n",
      "alabaster                     0.7.12\n",
      "altgraph                      0.17\n",
      "argcomplete                   1.10.3\n",
      "argon2-cffi                   20.1.0\n",
      "arrow                         1.2.2\n",
      "asgiref                       3.6.0\n",
      "astroid                       2.9.3\n",
      "async-generator               1.10\n",
      "atomicwrites                  1.4.0\n",
      "attrs                         21.2.0\n",
      "autopep8                      1.6.0\n",
      "Babel                         2.9.1\n",
      "backcall                      0.2.0\n",
      "backports.zoneinfo            0.2.1\n",
      "bcrypt                        3.2.0\n",
      "beautifulsoup4                4.8.2\n",
      "binaryornot                   0.4.4\n",
      "black                         22.1.0\n",
      "bleach                        3.3.0\n",
      "branca                        0.4.2\n",
      "bs4                           0.0.1\n",
      "certifi                       2021.5.30\n",
      "cffi                          1.14.5\n",
      "chardet                       3.0.4\n",
      "charset-normalizer            3.3.2\n",
      "click                         8.0.1\n",
      "cloudpickle                   2.0.0\n",
      "colorama                      0.4.4\n",
      "compressed-rtf                1.0.6\n",
      "cookiecutter                  1.7.3\n",
      "cryptography                  36.0.1\n",
      "cycler                        0.10.0\n",
      "debugpy                       1.5.1\n",
      "decorator                     5.0.9\n",
      "defusedxml                    0.7.1\n",
      "diff-match-patch              20200713\n",
      "Django                        4.1.7\n",
      "docutils                      0.17.1\n",
      "docx2txt                      0.8\n",
      "ebcdic                        1.1.1\n",
      "EbookLib                      0.17.1\n",
      "entrypoints                   0.3\n",
      "et-xmlfile                    1.1.0\n",
      "extract-msg                   0.28.7\n",
      "filelock                      3.9.0\n",
      "flake8                        4.0.1\n",
      "folium                        0.12.1\n",
      "future                        0.18.2\n",
      "googlemaps                    4.5.3\n",
      "greenlet                      2.0.2\n",
      "html5lib                      1.1\n",
      "idna                          2.10\n",
      "imagesize                     1.3.0\n",
      "IMAPClient                    2.1.0\n",
      "importlib-metadata            4.10.1\n",
      "inflection                    0.5.1\n",
      "intervaltree                  3.1.0\n",
      "ipykernel                     6.9.0\n",
      "ipython                       7.24.1\n",
      "ipython-genutils              0.2.0\n",
      "ipywidgets                    7.6.3\n",
      "isort                         5.10.1\n",
      "jedi                          0.18.0\n",
      "jellyfish                     0.9.0\n",
      "Jinja2                        3.0.1\n",
      "jinja2-time                   0.2.0\n",
      "joblib                        1.3.2\n",
      "jsonschema                    3.2.0\n",
      "jupyter                       1.0.0\n",
      "jupyter-client                7.1.2\n",
      "jupyter-console               6.4.0\n",
      "jupyter-core                  4.7.1\n",
      "jupyterlab-pygments           0.1.2\n",
      "jupyterlab-widgets            1.0.0\n",
      "jupyterthemes                 0.20.0\n",
      "keyring                       23.5.0\n",
      "kiwisolver                    1.3.1\n",
      "lazy-object-proxy             1.7.1\n",
      "lesscpy                       0.14.0\n",
      "littleutils                   0.2.2\n",
      "lxml                          4.6.3\n",
      "MarkupSafe                    2.0.1\n",
      "matplotlib                    3.4.2\n",
      "matplotlib-inline             0.1.2\n",
      "mccabe                        0.6.1\n",
      "mistune                       0.8.4\n",
      "mpmath                        1.2.1\n",
      "mypy-extensions               0.4.3\n",
      "mysql                         0.0.3\n",
      "mysqlclient                   2.0.3\n",
      "nbclient                      0.5.3\n",
      "nbconvert                     6.0.7\n",
      "nbformat                      5.1.3\n",
      "nest-asyncio                  1.5.1\n",
      "networkx                      3.0\n",
      "nltk                          3.6.2\n",
      "notebook                      6.4.0\n",
      "numpy                         1.20.3\n",
      "numpydoc                      1.2\n",
      "oauthlib                      3.2.2\n",
      "olefile                       0.46\n",
      "opencv-python                 4.5.2.54\n",
      "openpyxl                      3.0.7\n",
      "outdated                      0.2.1\n",
      "packaging                     21.3\n",
      "pandas                        1.2.5\n",
      "pandas-flavor                 0.2.0\n",
      "pandocfilters                 1.4.3\n",
      "paramiko                      2.9.2\n",
      "parso                         0.8.2\n",
      "pathspec                      0.9.0\n",
      "patsy                         0.5.2\n",
      "pdfminer.six                  20191110\n",
      "pdfminer3k                    1.3.4\n",
      "pefile                        2021.5.24\n",
      "pexpect                       4.8.0\n",
      "pickleshare                   0.7.5\n",
      "Pillow                        9.3.0\n",
      "pingouin                      0.5.1\n",
      "pip                           24.0\n",
      "platformdirs                  2.4.1\n",
      "pluggy                        1.0.0\n",
      "ply                           3.11\n",
      "poyo                          0.5.0\n",
      "prometheus-client             0.11.0\n",
      "prompt-toolkit                3.0.19\n",
      "psutil                        5.9.0\n",
      "psycopg2-binary               2.9.6\n",
      "ptyprocess                    0.7.0\n",
      "pycodestyle                   2.8.0\n",
      "pycparser                     2.20\n",
      "pycryptodome                  3.10.1\n",
      "pydocstyle                    6.1.1\n",
      "pyflakes                      2.4.0\n",
      "Pygments                      2.9.0\n",
      "pyinstaller                   4.3\n",
      "pyinstaller-hooks-contrib     2021.2\n",
      "pylint                        2.12.2\n",
      "pyls-spyder                   0.4.0\n",
      "PyNaCl                        1.5.0\n",
      "pyparsing                     2.4.7\n",
      "PyPDF2                        1.26.0\n",
      "pyperclip                     1.8.2\n",
      "PyQt5                         5.12.3\n",
      "PyQt5-sip                     12.9.1\n",
      "PyQtWebEngine                 5.12.1\n",
      "pyrsistent                    0.17.3\n",
      "PySocks                       1.7.1\n",
      "python-dateutil               2.8.1\n",
      "python-lsp-black              1.1.0\n",
      "python-lsp-jsonrpc            1.0.0\n",
      "python-lsp-server             1.3.3\n",
      "python-pptx                   0.6.19\n",
      "python-slugify                5.0.2\n",
      "pytz                          2021.1\n",
      "pywin32                       301\n",
      "pywin32-ctypes                0.2.0\n",
      "pywinpty                      1.1.2\n",
      "pyzmq                         22.1.0\n",
      "QDarkStyle                    3.0.2\n",
      "qstylizer                     0.2.1\n",
      "QtAwesome                     1.1.1\n",
      "qtconsole                     5.2.2\n",
      "QtPy                          1.9.0\n",
      "regex                         2021.8.21\n",
      "requests                      2.31.0\n",
      "requests-oauthlib             1.3.1\n",
      "rope                          0.22.0\n",
      "Rtree                         0.9.7\n",
      "scikit-learn                  1.3.2\n",
      "scipy                         1.7.1\n",
      "seaborn                       0.11.2\n",
      "selenium                      3.141.0\n",
      "Send2Trash                    1.5.0\n",
      "setuptools                    60.8.1\n",
      "simplejson                    3.17.3\n",
      "six                           1.12.0\n",
      "sklearn                       0.0\n",
      "snowballstemmer               2.2.0\n",
      "sortedcontainers              2.4.0\n",
      "soupsieve                     2.2.1\n",
      "SpeechRecognition             3.8.1\n",
      "Sphinx                        4.4.0\n",
      "sphinxcontrib-applehelp       1.0.2\n",
      "sphinxcontrib-devhelp         1.0.2\n",
      "sphinxcontrib-htmlhelp        2.0.0\n",
      "sphinxcontrib-jsmath          1.0.1\n",
      "sphinxcontrib-qthelp          1.0.3\n",
      "sphinxcontrib-serializinghtml 1.1.5\n",
      "spyder                        5.2.2\n",
      "spyder-kernels                2.2.1\n",
      "SQLAlchemy                    2.0.9\n",
      "sqlparse                      0.4.3\n",
      "statsmodels                   0.13.2\n",
      "sympy                         1.11.1\n",
      "tabulate                      0.8.9\n",
      "terminado                     0.10.1\n",
      "testpath                      0.5.0\n",
      "text-unidecode                1.3\n",
      "textdistance                  4.2.2\n",
      "textract                      1.6.4\n",
      "threadpoolctl                 3.0.0\n",
      "three-merge                   0.1.1\n",
      "tinycss2                      1.1.1\n",
      "toml                          0.10.2\n",
      "tomli                         2.0.1\n",
      "torch                         2.0.1+cu117\n",
      "torchaudio                    2.0.2+cu117\n",
      "torchvision                   0.15.2+cu117\n",
      "tornado                       6.1\n",
      "tqdm                          4.62.2\n",
      "traitlets                     5.1.1\n",
      "tweepy                        4.14.0\n",
      "typing_extensions             4.5.0\n",
      "tzdata                        2021.1\n",
      "tzlocal                       3.0\n",
      "ujson                         5.1.0\n",
      "urllib3                       1.26.5\n",
      "watchdog                      2.1.6\n",
      "wcwidth                       0.2.5\n",
      "webencodings                  0.5.1\n",
      "widgetsnbextension            3.5.1\n",
      "wordcloud                     1.8.1\n",
      "wrapt                         1.13.3\n",
      "xarray                        2022.3.0\n",
      "xlrd                          1.2.0\n",
      "XlsxWriter                    3.0.1\n",
      "xlwt                          1.3.0\n",
      "yapf                          0.32.0\n",
      "zipp                          3.7.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pyder (c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TfidfVectorizer\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpairwise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cosine_similarity\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Convert tokenized queries and abstracts back to string format for TF-IDF vectorization\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Convert tokenized queries and abstracts back to string format for TF-IDF vectorization\n",
    "queries_str = [\" \".join(tokens) for tokens in tokenized_qry.values()] # For each query\n",
    "abstracts_str = [\" \".join(tokens) for tokens in tokenized_abstr.values()] # For each abstract\n",
    "\n",
    "# Combine queries and abstracts for TF-IDF vectorization (to ensure vocabulary matches)\n",
    "combined_texts = queries_str + abstracts_str\n",
    "\n",
    "# Initialize and fit TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(combined_texts)\n",
    "\n",
    "# Split TF-IDF matrix back into queries and abstracts\n",
    "tfidf_queries = tfidf_matrix[:len(queries_str)]\n",
    "tfidf_abstracts = tfidf_matrix[len(queries_str):]\n",
    "\n",
    "# Compute cosine similarity between each query and all abstracts\n",
    "cosine_similarities = cosine_similarity(tfidf_queries, tfidf_abstracts)\n",
    "        \n",
    "output_lines = []\n",
    "\n",
    "# Minimum number of matches to output for each query\n",
    "min_matches = 100\n",
    "\n",
    "# Iterate over each query's cosine similarities with abstracts\n",
    "for query_index, similarities in enumerate(cosine_similarities):\n",
    "    # Sort the indices of abstracts based on similarity scores in descending order\n",
    "    sorted_indices = np.argsort(similarities)[::-1]\n",
    "    # Filter out indices where similarity score is 0, but ensure at least 100\n",
    "    non_zero_indices = [index for index in sorted_indices if similarities[index] > 0]\n",
    "    \n",
    "    # If fewer than min_matches, append indices with zero similarity\n",
    "    if len(non_zero_indices) < min_matches:\n",
    "        zero_indices = [index for index in sorted_indices if similarities[index] == 0]\n",
    "        required_zeros = min_matches - len(non_zero_indices)\n",
    "        non_zero_indices.extend(zero_indices[:required_zeros])\n",
    "    \n",
    "    # Iterate over filtered and possibly extended indices to prepare lines for the output file\n",
    "    for rank, abstract_index in enumerate(non_zero_indices):\n",
    "        # Format : query_id, abstract_id, cosine_similarity_score\n",
    "        line = f\"{query_index + 1} {abstract_index + 1} {similarities[abstract_index]:.12f}\"\n",
    "        output_lines.append(line)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_path = 'output.txt'\n",
    "with open(output_file_path, 'w') as file:\n",
    "    # Write each line to the file\n",
    "    for line in output_lines:\n",
    "        file.write(line + '\\n')  # Each entry appears on a new line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "# Function to calculate IDF scores for each word\n",
    "def calculate_idf_scores(tokenized_content) :\n",
    "    word_document_frq = defaultdict(int)\n",
    "    total_documents = len(tokenized_abstr)\n",
    "\n",
    "    # Count each word frequency in documents\n",
    "    for doc in tokenized_abstr :\n",
    "        unique_words = set(doc)\n",
    "        for word in unique_words :\n",
    "            word_document_frq[word] += 1\n",
    "\n",
    "    # Calculate IDF scores\n",
    "    idfs = {word: np.log(total_documents / (1 + freq)) for word, freq in word_document_frq.items()}\n",
    "    return idfs\n",
    "\n",
    "# IDF scores for queries and abstracts\n",
    "idfs_queries = calculate_idf_scores(tokenized_qry.values())\n",
    "idfs_abstracts = calculate_idf_scores(tokenized_abstr.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# Function to calculate TF-IDF scores using calculated IDF scores\n",
    "def calculate_tfidf_scores(tokenized_data, idfs) :\n",
    "    tfidf_scores = {}\n",
    "    # Count term frequency\n",
    "    for key, tokens in tokenized_data.items() :\n",
    "        term_counts = Counter(tokens)\n",
    "        total_terms = len(tokens)\n",
    "\n",
    "        # Calculate TF-IDF scores\n",
    "        tf_scores = {term: count / total_terms for term, count in term_counts.items()}\n",
    "        tfidf_scores[key] = {term: tf_scores[term] * idfs.get(term, 0) for term in tf_scores}\n",
    "    \n",
    "    return tfidf_scores\n",
    "\n",
    "# TF-IDF scores for queries and abstracts\n",
    "tfidf_queries = calculate_tfidf_scores(tokenized_qry, idfs_queries)\n",
    "tfidf_abstracts = calculate_tfidf_scores(tokenized_abstr, idfs_abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
